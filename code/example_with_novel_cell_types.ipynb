{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scEMAIL_model import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the preprocessed target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataname: Neonatal_rib\n"
     ]
    }
   ],
   "source": [
    "dataset='Neonatal_rib'\n",
    "print(\"dataname:\", dataset)\n",
    "adata = sc.read(\"/data/wanh/scEMAIL/real_data/{}_adata.h5ad\".format(dataset))\n",
    "X = adata.X.astype(np.float32)\n",
    "with open('/data/wanh/scEMAIL/real_data/{}_count_X.csv'.format(dataset),newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    count_X = []\n",
    "    for row in spamreader:\n",
    "        count_X.append([round(float(j)) for j in row])\n",
    "count_X = np.array(count_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the pre-trained source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source cell types: 13 ['B cell', 'Dividing cell', 'Endothelial cell', 'Erythroblast', 'Granulocyte', 'Macrophage', 'Muscle cell', 'Neuron', 'Neutrophil', 'Oligodendrocyte', 'Osteoblast', 'Osteoclast', 'Stromal cell']\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"/data/wanh/scEMAIL/source_model/real_data/AE_weights_{}.pth.tar\".format(dataset))\n",
    "source_class_num = checkpoint['ae_state_dict'][\"classifier.0.bias\"].size()[0]\n",
    "model = target_model(input_dim=adata.n_vars, z_dim=32, n_clusters=source_class_num,\n",
    "                             encodeLayer=[256, 64], decodeLayer=[64, 256], sigma=2.5).cuda()\n",
    "model_dict = model.state_dict()\n",
    "for i in checkpoint['ae_state_dict']:\n",
    "    model_dict[i] = checkpoint['ae_state_dict'][i]\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "with open('/data/wanh/scEMAIL/real_data/{}_annotation.csv'.format(dataset),newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    source_annotation = []\n",
    "    for row in spamreader:\n",
    "        source_annotation.append(row[0])\n",
    "print(\"source cell types:\",source_class_num, source_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### source model adaptation towards target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 1217\n",
      "number of class: 13\n",
      "bimodality of dip test: 0.0 True\n",
      "bimodality coefficient:(>0.555 indicates bimodality) 0.8637358932974857 True\n",
      "ood sample exists: True\n",
      "Pretrain epoch [1/1], ZINB loss:0.1755\n",
      "Pretrain epoch [2/1], ZINB loss:0.1828\n",
      "Pretrain epoch [3/1], ZINB loss:0.1768\n",
      "Pretrain epoch [4/1], ZINB loss:0.1696\n",
      "Pretrain epoch [5/1], ZINB loss:0.1756\n",
      "Pretrain epoch [1/2], ZINB loss:0.1766\n",
      "Pretrain epoch [2/2], ZINB loss:0.1829\n",
      "Pretrain epoch [3/2], ZINB loss:0.1704\n",
      "Pretrain epoch [4/2], ZINB loss:0.1728\n",
      "Pretrain epoch [5/2], ZINB loss:0.1705\n",
      "Pretrain epoch [1/3], ZINB loss:0.1708\n",
      "Pretrain epoch [2/3], ZINB loss:0.1669\n",
      "Pretrain epoch [3/3], ZINB loss:0.1886\n",
      "Pretrain epoch [4/3], ZINB loss:0.1738\n",
      "Pretrain epoch [5/3], ZINB loss:0.1685\n",
      "Pretrain epoch [1/4], ZINB loss:0.1701\n",
      "Pretrain epoch [2/4], ZINB loss:0.1735\n",
      "Pretrain epoch [3/4], ZINB loss:0.1739\n",
      "Pretrain epoch [4/4], ZINB loss:0.1818\n",
      "Pretrain epoch [5/4], ZINB loss:0.1651\n",
      "Pretrain epoch [1/5], ZINB loss:0.1731\n",
      "Pretrain epoch [2/5], ZINB loss:0.1735\n",
      "Pretrain epoch [3/5], ZINB loss:0.1712\n",
      "Pretrain epoch [4/5], ZINB loss:0.1813\n",
      "Pretrain epoch [5/5], ZINB loss:0.1639\n",
      "Pretrain epoch [1/6], ZINB loss:0.1684\n",
      "Pretrain epoch [2/6], ZINB loss:0.1832\n",
      "Pretrain epoch [3/6], ZINB loss:0.1767\n",
      "Pretrain epoch [4/6], ZINB loss:0.1627\n",
      "Pretrain epoch [5/6], ZINB loss:0.1698\n",
      "Pretrain epoch [1/7], ZINB loss:0.1816\n",
      "Pretrain epoch [2/7], ZINB loss:0.1620\n",
      "Pretrain epoch [3/7], ZINB loss:0.1762\n",
      "Pretrain epoch [4/7], ZINB loss:0.1678\n",
      "Pretrain epoch [5/7], ZINB loss:0.1720\n",
      "Pretrain epoch [1/8], ZINB loss:0.1710\n",
      "Pretrain epoch [2/8], ZINB loss:0.1730\n",
      "Pretrain epoch [3/8], ZINB loss:0.1717\n",
      "Pretrain epoch [4/8], ZINB loss:0.1735\n",
      "Pretrain epoch [5/8], ZINB loss:0.1692\n",
      "Pretrain epoch [1/9], ZINB loss:0.1748\n",
      "Pretrain epoch [2/9], ZINB loss:0.1729\n",
      "Pretrain epoch [3/9], ZINB loss:0.1693\n",
      "Pretrain epoch [4/9], ZINB loss:0.1700\n",
      "Pretrain epoch [5/9], ZINB loss:0.1695\n",
      "Pretrain epoch [1/10], ZINB loss:0.1647\n",
      "Pretrain epoch [2/10], ZINB loss:0.1742\n",
      "Pretrain epoch [3/10], ZINB loss:0.1736\n",
      "Pretrain epoch [4/10], ZINB loss:0.1767\n",
      "Pretrain epoch [5/10], ZINB loss:0.1683\n",
      "Midtrain epoch [1/11], ZINB loss:0.1682,  neighbor loss 1:-2.6604, expanded neighbor loss 1:-2.2244, self loss:-0.8979\n",
      "Midtrain epoch [2/11], ZINB loss:0.1714,  neighbor loss 1:-2.3788, expanded neighbor loss 1:-2.1859, self loss:-0.8682\n",
      "Midtrain epoch [3/11], ZINB loss:0.1751,  neighbor loss 1:-2.3433, expanded neighbor loss 1:-2.1877, self loss:-0.8623\n",
      "Midtrain epoch [4/11], ZINB loss:0.1646,  neighbor loss 1:-2.3699, expanded neighbor loss 1:-2.2803, self loss:-0.9094\n",
      "Midtrain epoch [5/11], ZINB loss:0.1770,  neighbor loss 1:-2.5577, expanded neighbor loss 1:-2.2502, self loss:-0.8874\n",
      "current error: tensor(0.0051, device='cuda:0')\n",
      "Midtrain epoch [1/12], ZINB loss:0.1690,  neighbor loss 1:-2.6016, expanded neighbor loss 1:-2.2548, self loss:-0.9055\n",
      "Midtrain epoch [2/12], ZINB loss:0.1718,  neighbor loss 1:-2.6331, expanded neighbor loss 1:-2.2637, self loss:-0.9028\n",
      "Midtrain epoch [3/12], ZINB loss:0.1649,  neighbor loss 1:-2.7396, expanded neighbor loss 1:-2.2721, self loss:-0.9091\n",
      "Midtrain epoch [4/12], ZINB loss:0.1716,  neighbor loss 1:-2.7752, expanded neighbor loss 1:-2.2826, self loss:-0.9067\n",
      "Midtrain epoch [5/12], ZINB loss:0.1859,  neighbor loss 1:-2.4827, expanded neighbor loss 1:-2.2020, self loss:-0.8618\n",
      "current error: tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "bimodality,pred_celltype = model.fit(x=X, annotation=source_annotation, X_raw=count_X,\n",
    "                           size_factor=adata.obs.size_factors,pretrain_epoch=10,midtrain_epoch=20,\n",
    "                           K=5, KK=5, alpha=0.1)\n",
    "time_cost = time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate annotation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novel cell types exist: True\n",
      "target cell types: ['B cell' 'Cartilage cell' 'Dividing cell' 'Endothelial cell'\n",
      " 'Erythroblast' 'Granulocyte' 'Macrophage' 'Muscle cell' 'Neuron'\n",
      " 'Neutrophil' 'Osteoblast' 'Osteoclast' 'Stromal cell']\n",
      "novel cell type: ['Cartilage cell']\n",
      "        Dataset   Accuracy of known Accuracy of unknown      Total accuracy  \\\n",
      "0  Neonatal_rib  0.8752025931928687  0.9433333333333334  0.9087921117502055   \n",
      "\n",
      "              H-score      Time consuming  \n",
      "0  0.9079917174423889  12.635180473327637  \n"
     ]
    }
   ],
   "source": [
    "cellname = np.array(adata.obs[\"celltype\"])\n",
    "print(\"novel cell types exist:\",bimodality)\n",
    "print(\"target cell types:\",np.unique(cellname))\n",
    "print(\"novel cell type:\",[j for j in np.unique(cellname) if j not in source_annotation])\n",
    "true_known,true_unknown,right_pred_known,right_pred_unknown = 0,0,0,0\n",
    "for i in range(len(cellname)):\n",
    "    if cellname[i] not in source_annotation:\n",
    "        true_unknown += 1\n",
    "        if pred_celltype[i]==\"Unknown\":\n",
    "                right_pred_unknown += 1\n",
    "    else:\n",
    "        true_known += 1\n",
    "        if pred_celltype[i]== cellname[i]:\n",
    "            right_pred_known += 1\n",
    "accuracy_known=right_pred_known / true_known\n",
    "accuracy_unknown=right_pred_unknown / true_unknown\n",
    "total_accuracy= (right_pred_known + right_pred_unknown) / len(cellname)\n",
    "H_score=2 * accuracy_known * accuracy_unknown / (accuracy_known + accuracy_unknown)\n",
    "result=np.array([[dataset,accuracy_known, accuracy_unknown, total_accuracy, H_score, time_cost]])\n",
    "output = pd.DataFrame(result,\n",
    "                      columns=[\"Dataset\",\"Accuracy of known\", \"Accuracy of unknown\",\"Total accuracy\", \"H-score\",\n",
    "                               \"Time consuming\"])\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
