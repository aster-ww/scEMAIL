{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52d6a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scEMAIL_model import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d18e21",
   "metadata": {},
   "source": [
    "### load the preprocessed target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e205d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataname: Pancreas\n"
     ]
    }
   ],
   "source": [
    "dataset='Pancreas'\n",
    "print(\"dataname:\", dataset)\n",
    "adata = sc.read(\"/data/wanh/scEMAIL/real_data/{}_adata.h5ad\".format(dataset))\n",
    "X = adata.X.astype(np.float32)\n",
    "with open('/data/wanh/scEMAIL/real_data/{}_count_X.csv'.format(dataset),newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    count_X = []\n",
    "    for row in spamreader:\n",
    "        count_X.append([round(float(j)) for j in row])\n",
    "count_X = np.array(count_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4461681",
   "metadata": {},
   "source": [
    "### load the pre-trained source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cbca6134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source cell types: 9 ['acinar', 'alpha', 'beta', 'delta', 'ductal', 'endothelial', 'epsilon', 'gamma', 'mesenchymal']\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"/data/wanh/scEMAIL/source_model/real_data/AE_weights_{}.pth.tar\".format(dataset))\n",
    "source_class_num = checkpoint['ae_state_dict'][\"classifier.0.bias\"].size()[0]\n",
    "model = target_model(input_dim=adata.n_vars, z_dim=32, n_clusters=source_class_num,\n",
    "                             encodeLayer=[256, 64], decodeLayer=[64, 256], sigma=2.5).cuda()\n",
    "model_dict = model.state_dict()\n",
    "for i in checkpoint['ae_state_dict']:\n",
    "    model_dict[i] = checkpoint['ae_state_dict'][i]\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "with open('/data/wanh/scEMAIL/real_data/{}_annotation.csv'.format(dataset),newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    source_annotation = []\n",
    "    for row in spamreader:\n",
    "        source_annotation.append(row[0])\n",
    "print(\"source cell types:\",source_class_num, source_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc0c5319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 2282\n",
      "number of class: 9\n",
      "bimodality of dip test: 0.7144285571442855 False\n",
      "bimodality coefficient:(>0.555 indicates bimodality) 0.4676114187132847 False\n",
      "ood sample exists: False\n",
      "Pretrain epoch [1/1], ZINB loss:5.3878\n",
      "Pretrain epoch [2/1], ZINB loss:4.6107\n",
      "Pretrain epoch [3/1], ZINB loss:4.0291\n",
      "Pretrain epoch [4/1], ZINB loss:3.8227\n",
      "Pretrain epoch [5/1], ZINB loss:3.3147\n",
      "Pretrain epoch [6/1], ZINB loss:3.1258\n",
      "Pretrain epoch [7/1], ZINB loss:3.0232\n",
      "Pretrain epoch [8/1], ZINB loss:2.9984\n",
      "Pretrain epoch [9/1], ZINB loss:2.6662\n",
      "Pretrain epoch [1/2], ZINB loss:2.4081\n",
      "Pretrain epoch [2/2], ZINB loss:2.7254\n",
      "Pretrain epoch [3/2], ZINB loss:2.4217\n",
      "Pretrain epoch [4/2], ZINB loss:2.4856\n",
      "Pretrain epoch [5/2], ZINB loss:2.1758\n",
      "Pretrain epoch [6/2], ZINB loss:2.1847\n",
      "Pretrain epoch [7/2], ZINB loss:2.1552\n",
      "Pretrain epoch [8/2], ZINB loss:1.9722\n",
      "Pretrain epoch [9/2], ZINB loss:2.0193\n",
      "Pretrain epoch [1/3], ZINB loss:1.9396\n",
      "Pretrain epoch [2/3], ZINB loss:1.8370\n",
      "Pretrain epoch [3/3], ZINB loss:1.9294\n",
      "Pretrain epoch [4/3], ZINB loss:1.8579\n",
      "Pretrain epoch [5/3], ZINB loss:1.7093\n",
      "Pretrain epoch [6/3], ZINB loss:1.6481\n",
      "Pretrain epoch [7/3], ZINB loss:1.6620\n",
      "Pretrain epoch [8/3], ZINB loss:1.6535\n",
      "Pretrain epoch [9/3], ZINB loss:1.6897\n",
      "Pretrain epoch [1/4], ZINB loss:1.5987\n",
      "Pretrain epoch [2/4], ZINB loss:1.5330\n",
      "Pretrain epoch [3/4], ZINB loss:1.4425\n",
      "Pretrain epoch [4/4], ZINB loss:1.5472\n",
      "Pretrain epoch [5/4], ZINB loss:1.4076\n",
      "Pretrain epoch [6/4], ZINB loss:1.5047\n",
      "Pretrain epoch [7/4], ZINB loss:1.4507\n",
      "Pretrain epoch [8/4], ZINB loss:1.4120\n",
      "Pretrain epoch [9/4], ZINB loss:1.4403\n",
      "Pretrain epoch [1/5], ZINB loss:1.3646\n",
      "Pretrain epoch [2/5], ZINB loss:1.3683\n",
      "Pretrain epoch [3/5], ZINB loss:1.3537\n",
      "Pretrain epoch [4/5], ZINB loss:1.2759\n",
      "Pretrain epoch [5/5], ZINB loss:1.2994\n",
      "Pretrain epoch [6/5], ZINB loss:1.3088\n",
      "Pretrain epoch [7/5], ZINB loss:1.2895\n",
      "Pretrain epoch [8/5], ZINB loss:1.1925\n",
      "Pretrain epoch [9/5], ZINB loss:1.2826\n",
      "Pretrain epoch [1/6], ZINB loss:1.1846\n",
      "Pretrain epoch [2/6], ZINB loss:1.2154\n",
      "Pretrain epoch [3/6], ZINB loss:1.2361\n",
      "Pretrain epoch [4/6], ZINB loss:1.1523\n",
      "Pretrain epoch [5/6], ZINB loss:1.1898\n",
      "Pretrain epoch [6/6], ZINB loss:1.1190\n",
      "Pretrain epoch [7/6], ZINB loss:1.1780\n",
      "Pretrain epoch [8/6], ZINB loss:1.1857\n",
      "Pretrain epoch [9/6], ZINB loss:1.1066\n",
      "Pretrain epoch [1/7], ZINB loss:1.1839\n",
      "Pretrain epoch [2/7], ZINB loss:1.0850\n",
      "Pretrain epoch [3/7], ZINB loss:1.0901\n",
      "Pretrain epoch [4/7], ZINB loss:1.1124\n",
      "Pretrain epoch [5/7], ZINB loss:1.1444\n",
      "Pretrain epoch [6/7], ZINB loss:1.1030\n",
      "Pretrain epoch [7/7], ZINB loss:1.0425\n",
      "Pretrain epoch [8/7], ZINB loss:1.0860\n",
      "Pretrain epoch [9/7], ZINB loss:1.0394\n",
      "Pretrain epoch [1/8], ZINB loss:1.0683\n",
      "Pretrain epoch [2/8], ZINB loss:1.0368\n",
      "Pretrain epoch [3/8], ZINB loss:1.0477\n",
      "Pretrain epoch [4/8], ZINB loss:1.0251\n",
      "Pretrain epoch [5/8], ZINB loss:1.1083\n",
      "Pretrain epoch [6/8], ZINB loss:1.0125\n",
      "Pretrain epoch [7/8], ZINB loss:1.0114\n",
      "Pretrain epoch [8/8], ZINB loss:1.0041\n",
      "Pretrain epoch [9/8], ZINB loss:1.0999\n",
      "Pretrain epoch [1/9], ZINB loss:1.0040\n",
      "Pretrain epoch [2/9], ZINB loss:0.9612\n",
      "Pretrain epoch [3/9], ZINB loss:1.0071\n",
      "Pretrain epoch [4/9], ZINB loss:0.9547\n",
      "Pretrain epoch [5/9], ZINB loss:1.0419\n",
      "Pretrain epoch [6/9], ZINB loss:1.0302\n",
      "Pretrain epoch [7/9], ZINB loss:1.0079\n",
      "Pretrain epoch [8/9], ZINB loss:1.0045\n",
      "Pretrain epoch [9/9], ZINB loss:0.9613\n",
      "Pretrain epoch [1/10], ZINB loss:0.9672\n",
      "Pretrain epoch [2/10], ZINB loss:0.9737\n",
      "Pretrain epoch [3/10], ZINB loss:0.9648\n",
      "Pretrain epoch [4/10], ZINB loss:0.9693\n",
      "Pretrain epoch [5/10], ZINB loss:0.9529\n",
      "Pretrain epoch [6/10], ZINB loss:0.9678\n",
      "Pretrain epoch [7/10], ZINB loss:0.9790\n",
      "Pretrain epoch [8/10], ZINB loss:1.0209\n",
      "Pretrain epoch [9/10], ZINB loss:0.9972\n",
      "Midtrain epoch [1/11], ZINB loss:0.9218,  neighbor loss 1:-1.4507, expanded neighbor loss 1:-1.4646, self loss:-0.5694\n",
      "Midtrain epoch [2/11], ZINB loss:0.9708,  neighbor loss 1:-1.3202, expanded neighbor loss 1:-1.4370, self loss:-0.5646\n",
      "Midtrain epoch [3/11], ZINB loss:0.9748,  neighbor loss 1:-1.7360, expanded neighbor loss 1:-1.5628, self loss:-0.6273\n",
      "Midtrain epoch [4/11], ZINB loss:1.0232,  neighbor loss 1:-1.6005, expanded neighbor loss 1:-1.6044, self loss:-0.6542\n",
      "Midtrain epoch [5/11], ZINB loss:0.9343,  neighbor loss 1:-1.7913, expanded neighbor loss 1:-1.6617, self loss:-0.6724\n",
      "Midtrain epoch [6/11], ZINB loss:0.9221,  neighbor loss 1:-1.7906, expanded neighbor loss 1:-1.6907, self loss:-0.6740\n",
      "Midtrain epoch [7/11], ZINB loss:0.9874,  neighbor loss 1:-1.8977, expanded neighbor loss 1:-1.7304, self loss:-0.6889\n",
      "Midtrain epoch [8/11], ZINB loss:0.9509,  neighbor loss 1:-1.8806, expanded neighbor loss 1:-1.7536, self loss:-0.6948\n",
      "Midtrain epoch [9/11], ZINB loss:0.8797,  neighbor loss 1:-1.8994, expanded neighbor loss 1:-1.7679, self loss:-0.6951\n",
      "current error: tensor(0.0570, device='cuda:0')\n",
      "Midtrain epoch [1/12], ZINB loss:0.9120,  neighbor loss 1:-1.9859, expanded neighbor loss 1:-1.7899, self loss:-0.7092\n",
      "Midtrain epoch [2/12], ZINB loss:0.9782,  neighbor loss 1:-2.0924, expanded neighbor loss 1:-1.8294, self loss:-0.7217\n",
      "Midtrain epoch [3/12], ZINB loss:0.9348,  neighbor loss 1:-2.0807, expanded neighbor loss 1:-1.8351, self loss:-0.7302\n",
      "Midtrain epoch [4/12], ZINB loss:0.9796,  neighbor loss 1:-1.9510, expanded neighbor loss 1:-1.8371, self loss:-0.7228\n",
      "Midtrain epoch [5/12], ZINB loss:0.9729,  neighbor loss 1:-2.0045, expanded neighbor loss 1:-1.8402, self loss:-0.7258\n",
      "Midtrain epoch [6/12], ZINB loss:0.9091,  neighbor loss 1:-1.8847, expanded neighbor loss 1:-1.8568, self loss:-0.7298\n",
      "Midtrain epoch [7/12], ZINB loss:0.9000,  neighbor loss 1:-1.9654, expanded neighbor loss 1:-1.8589, self loss:-0.7323\n",
      "Midtrain epoch [8/12], ZINB loss:0.9513,  neighbor loss 1:-2.1138, expanded neighbor loss 1:-1.8805, self loss:-0.7405\n",
      "Midtrain epoch [9/12], ZINB loss:0.9244,  neighbor loss 1:-2.0845, expanded neighbor loss 1:-1.8840, self loss:-0.7410\n",
      "current error: tensor(0.0245, device='cuda:0')\n",
      "Midtrain epoch [1/13], ZINB loss:0.9497,  neighbor loss 1:-2.0423, expanded neighbor loss 1:-1.8576, self loss:-0.7322\n",
      "Midtrain epoch [2/13], ZINB loss:0.9815,  neighbor loss 1:-2.1086, expanded neighbor loss 1:-1.9329, self loss:-0.7618\n",
      "Midtrain epoch [3/13], ZINB loss:0.8695,  neighbor loss 1:-1.9462, expanded neighbor loss 1:-1.8308, self loss:-0.7185\n",
      "Midtrain epoch [4/13], ZINB loss:0.9584,  neighbor loss 1:-2.0652, expanded neighbor loss 1:-1.8963, self loss:-0.7486\n",
      "Midtrain epoch [5/13], ZINB loss:0.9126,  neighbor loss 1:-2.1543, expanded neighbor loss 1:-1.9063, self loss:-0.7497\n",
      "Midtrain epoch [6/13], ZINB loss:0.9331,  neighbor loss 1:-2.2238, expanded neighbor loss 1:-1.9440, self loss:-0.7683\n",
      "Midtrain epoch [7/13], ZINB loss:0.9702,  neighbor loss 1:-2.2326, expanded neighbor loss 1:-1.9058, self loss:-0.7508\n",
      "Midtrain epoch [8/13], ZINB loss:0.9018,  neighbor loss 1:-1.9574, expanded neighbor loss 1:-1.9197, self loss:-0.7548\n",
      "Midtrain epoch [9/13], ZINB loss:0.8817,  neighbor loss 1:-1.9592, expanded neighbor loss 1:-1.9604, self loss:-0.7690\n",
      "current error: tensor(0.0110, device='cuda:0')\n",
      "Midtrain epoch [1/14], ZINB loss:0.9101,  neighbor loss 1:-2.0793, expanded neighbor loss 1:-1.9477, self loss:-0.7669\n",
      "Midtrain epoch [2/14], ZINB loss:0.9213,  neighbor loss 1:-2.1020, expanded neighbor loss 1:-1.9305, self loss:-0.7613\n",
      "Midtrain epoch [3/14], ZINB loss:0.9372,  neighbor loss 1:-2.2993, expanded neighbor loss 1:-1.9488, self loss:-0.7692\n",
      "Midtrain epoch [4/14], ZINB loss:0.8704,  neighbor loss 1:-1.9528, expanded neighbor loss 1:-1.9397, self loss:-0.7607\n",
      "Midtrain epoch [5/14], ZINB loss:0.8829,  neighbor loss 1:-2.3441, expanded neighbor loss 1:-1.9525, self loss:-0.7700\n",
      "Midtrain epoch [6/14], ZINB loss:0.9062,  neighbor loss 1:-2.1597, expanded neighbor loss 1:-1.9787, self loss:-0.7779\n",
      "Midtrain epoch [7/14], ZINB loss:0.9442,  neighbor loss 1:-1.6361, expanded neighbor loss 1:-1.9255, self loss:-0.7508\n",
      "Midtrain epoch [8/14], ZINB loss:0.9547,  neighbor loss 1:-1.9816, expanded neighbor loss 1:-1.9379, self loss:-0.7625\n",
      "Midtrain epoch [9/14], ZINB loss:0.9163,  neighbor loss 1:-2.1664, expanded neighbor loss 1:-1.9698, self loss:-0.7781\n",
      "current error: tensor(0.0066, device='cuda:0')\n",
      "Midtrain epoch [1/15], ZINB loss:0.9077,  neighbor loss 1:-2.1532, expanded neighbor loss 1:-1.9934, self loss:-0.7893\n",
      "Midtrain epoch [2/15], ZINB loss:0.9305,  neighbor loss 1:-2.0216, expanded neighbor loss 1:-1.9170, self loss:-0.7529\n",
      "Midtrain epoch [3/15], ZINB loss:0.9168,  neighbor loss 1:-2.0449, expanded neighbor loss 1:-1.9529, self loss:-0.7719\n",
      "Midtrain epoch [4/15], ZINB loss:0.8895,  neighbor loss 1:-2.0059, expanded neighbor loss 1:-1.9577, self loss:-0.7689\n",
      "Midtrain epoch [5/15], ZINB loss:0.8905,  neighbor loss 1:-2.2217, expanded neighbor loss 1:-1.9868, self loss:-0.7857\n",
      "Midtrain epoch [6/15], ZINB loss:0.9220,  neighbor loss 1:-2.0016, expanded neighbor loss 1:-1.9749, self loss:-0.7789\n",
      "Midtrain epoch [7/15], ZINB loss:0.8969,  neighbor loss 1:-2.0776, expanded neighbor loss 1:-1.9564, self loss:-0.7718\n",
      "Midtrain epoch [8/15], ZINB loss:0.9009,  neighbor loss 1:-2.1029, expanded neighbor loss 1:-1.9248, self loss:-0.7560\n",
      "Midtrain epoch [9/15], ZINB loss:0.8920,  neighbor loss 1:-2.1932, expanded neighbor loss 1:-1.9761, self loss:-0.7799\n",
      "current error: tensor(0.0018, device='cuda:0')\n",
      "Midtrain epoch [1/16], ZINB loss:0.9199,  neighbor loss 1:-2.2436, expanded neighbor loss 1:-1.9796, self loss:-0.7832\n",
      "Midtrain epoch [2/16], ZINB loss:0.9117,  neighbor loss 1:-2.2625, expanded neighbor loss 1:-1.9882, self loss:-0.7876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midtrain epoch [3/16], ZINB loss:0.9099,  neighbor loss 1:-2.2737, expanded neighbor loss 1:-1.9736, self loss:-0.7788\n",
      "Midtrain epoch [4/16], ZINB loss:0.9095,  neighbor loss 1:-2.1520, expanded neighbor loss 1:-1.9541, self loss:-0.7724\n",
      "Midtrain epoch [5/16], ZINB loss:0.8957,  neighbor loss 1:-2.0071, expanded neighbor loss 1:-1.9756, self loss:-0.7785\n",
      "Midtrain epoch [6/16], ZINB loss:0.8781,  neighbor loss 1:-2.0473, expanded neighbor loss 1:-1.9866, self loss:-0.7824\n",
      "Midtrain epoch [7/16], ZINB loss:0.8905,  neighbor loss 1:-2.0994, expanded neighbor loss 1:-1.9750, self loss:-0.7778\n",
      "Midtrain epoch [8/16], ZINB loss:0.8719,  neighbor loss 1:-1.8907, expanded neighbor loss 1:-1.9811, self loss:-0.7813\n",
      "Midtrain epoch [9/16], ZINB loss:0.8730,  neighbor loss 1:-1.7444, expanded neighbor loss 1:-1.9746, self loss:-0.7746\n",
      "current error: tensor(0.0022, device='cuda:0')\n",
      "Midtrain epoch [1/17], ZINB loss:0.8734,  neighbor loss 1:-1.9539, expanded neighbor loss 1:-1.9792, self loss:-0.7832\n",
      "Midtrain epoch [2/17], ZINB loss:0.8931,  neighbor loss 1:-2.2805, expanded neighbor loss 1:-1.9836, self loss:-0.7830\n",
      "Midtrain epoch [3/17], ZINB loss:0.9000,  neighbor loss 1:-2.1574, expanded neighbor loss 1:-2.0019, self loss:-0.7945\n",
      "Midtrain epoch [4/17], ZINB loss:0.9063,  neighbor loss 1:-1.8665, expanded neighbor loss 1:-1.9577, self loss:-0.7685\n",
      "Midtrain epoch [5/17], ZINB loss:0.8790,  neighbor loss 1:-2.0326, expanded neighbor loss 1:-1.9731, self loss:-0.7748\n",
      "Midtrain epoch [6/17], ZINB loss:0.9027,  neighbor loss 1:-2.1350, expanded neighbor loss 1:-1.9734, self loss:-0.7776\n",
      "Midtrain epoch [7/17], ZINB loss:0.8621,  neighbor loss 1:-1.9527, expanded neighbor loss 1:-2.0016, self loss:-0.7893\n",
      "Midtrain epoch [8/17], ZINB loss:0.8981,  neighbor loss 1:-1.9357, expanded neighbor loss 1:-1.9626, self loss:-0.7753\n",
      "Midtrain epoch [9/17], ZINB loss:0.9039,  neighbor loss 1:-2.2027, expanded neighbor loss 1:-2.0008, self loss:-0.7952\n",
      "current error: tensor(0.0013, device='cuda:0')\n",
      "Midtrain epoch [1/18], ZINB loss:0.8314,  neighbor loss 1:-2.0154, expanded neighbor loss 1:-1.9720, self loss:-0.7770\n",
      "Midtrain epoch [2/18], ZINB loss:0.8474,  neighbor loss 1:-1.9377, expanded neighbor loss 1:-1.9877, self loss:-0.7836\n",
      "Midtrain epoch [3/18], ZINB loss:0.8847,  neighbor loss 1:-2.0925, expanded neighbor loss 1:-1.9589, self loss:-0.7694\n",
      "Midtrain epoch [4/18], ZINB loss:0.8597,  neighbor loss 1:-1.9896, expanded neighbor loss 1:-1.9785, self loss:-0.7815\n",
      "Midtrain epoch [5/18], ZINB loss:0.8962,  neighbor loss 1:-1.9962, expanded neighbor loss 1:-1.9652, self loss:-0.7767\n",
      "Midtrain epoch [6/18], ZINB loss:0.9376,  neighbor loss 1:-2.2322, expanded neighbor loss 1:-1.9877, self loss:-0.7945\n",
      "Midtrain epoch [7/18], ZINB loss:0.9057,  neighbor loss 1:-2.1447, expanded neighbor loss 1:-2.0155, self loss:-0.7999\n",
      "Midtrain epoch [8/18], ZINB loss:0.9044,  neighbor loss 1:-2.2356, expanded neighbor loss 1:-1.9930, self loss:-0.7874\n",
      "Midtrain epoch [9/18], ZINB loss:0.9296,  neighbor loss 1:-2.0015, expanded neighbor loss 1:-1.9912, self loss:-0.7859\n",
      "current error: tensor(0.0009, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "bimodality,pred_celltype = model.fit(x=X, annotation=source_annotation, X_raw=count_X,\n",
    "                           size_factor=adata.obs.size_factors,pretrain_epoch=10,midtrain_epoch=20,\n",
    "                                     K=5, KK=5, alpha=0.1)\n",
    "time_cost = time() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639a197",
   "metadata": {},
   "source": [
    "### calculate annotation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "599e406d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "novel cell types exist: False\n",
      "target cell types: ['acinar' 'alpha' 'beta' 'delta' 'ductal' 'mesenchymal']\n",
      "    Dataset      Total accuracy      Time consuming\n",
      "0  Pancreas  0.9666958808063103  13.497034788131714\n"
     ]
    }
   ],
   "source": [
    "print(\"novel cell types exist:\",bimodality)\n",
    "cellname = np.array(adata.obs[\"celltype\"])\n",
    "print(\"target cell types:\",np.unique(cellname))\n",
    "accuracy=np.mean(pred_celltype == cellname)\n",
    "result=np.array([[dataset,accuracy,time_cost]])\n",
    "output = pd.DataFrame(result,columns=[\"Dataset\",\"Total accuracy\",\"Time consuming\"])\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
